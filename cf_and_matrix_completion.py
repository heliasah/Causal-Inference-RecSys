# -*- coding: utf-8 -*-
"""CF and Matrix Completion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1toE1aZ0O7C9SkaBhmgNCyaALMaPC5_bQ
"""

import numpy as np
import pandas as pd
import os
import requests
import zipfile
from scipy.sparse import lil_matrix
from sklearn.model_selection import train_test_split


def download_and_extract_dataset():
    url = "http://files.grouplens.org/datasets/movielens/ml-100k.zip"
    zip_path = "ml-100k.zip"

    if not os.path.exists("ml-100k"):
        print("Downloading dataset...")
        response = requests.get(url)
        with open(zip_path, "wb") as f:
            f.write(response.content)

        print("Extracting dataset...")
        with zipfile.ZipFile(zip_path, "r") as zip_ref:
            zip_ref.extractall(".")
        os.remove(zip_path)


def load_ratings(file_path):
    df = pd.read_csv(file_path, sep='\t', header=None, names=['user_id', 'movie_id', 'rating', 'timestamp'])
    df['user_id'] -= 1
    df['movie_id'] -= 1
    return np.array(df[['user_id', 'movie_id', 'rating']])


class CollaborativeFiltering:
    def __init__(self, rating_matrix, n, item_based=True):
        self.rating_matrix = rating_matrix
        self.n_users, self.n_items = rating_matrix.shape
        self.n = n
        self.item_based = item_based

    def pearson_correlation_sim(self, id1, id2):
        if self.item_based:
            ratings_x = self.rating_matrix[:, id1]
            ratings_y = self.rating_matrix[:, id2]
        else:
            ratings_x = self.rating_matrix[id1, :]
            ratings_y = self.rating_matrix[id2, :]

        common_ratings = np.nonzero(np.logical_and(ratings_x > 0, ratings_y > 0))[0]

        if len(common_ratings) == 0:
            return 0

        rx_common = ratings_x[common_ratings]
        ry_common = ratings_y[common_ratings]

        rx_mean = np.mean(rx_common)
        ry_mean = np.mean(ry_common)

        rx_minus_mean = rx_common - rx_mean
        ry_minus_mean = ry_common - ry_mean

        denominator = np.linalg.norm(rx_minus_mean) * np.linalg.norm(ry_minus_mean)
        if denominator == 0:
            return 0

        return np.dot(rx_minus_mean, ry_minus_mean) / denominator

    def n_most_similar_items(self, item_id, user_id):
        similarities = [
            (id2, self.pearson_correlation_sim(item_id, id2))
            for id2 in range(self.n_items)
            if self.rating_matrix[user_id, id2] > 0 and id2 != item_id
        ]

        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:self.n]

        if not similarities:
            return [], []

        return zip(*similarities)

    def n_most_similar_users(self, user_id, item_id):
        similarities = [
            (id2, self.pearson_correlation_sim(user_id, id2))
            for id2 in range(self.n_users)
            if self.rating_matrix[id2, item_id] > 0 and id2 != user_id
        ]

        similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[:self.n]

        if not similarities:
            return [], []

        return zip(*similarities)

    def predict_rating(self, user_id, item_id):
        if self.item_based:
            similar_items, similarity_scores = self.n_most_similar_items(item_id, user_id)
            if not similar_items:
                return np.mean(self.rating_matrix[self.rating_matrix > 0])
            ratings = self.rating_matrix[user_id, list(similar_items)]
        else:
            similar_users, similarity_scores = self.n_most_similar_users(user_id, item_id)
            if not similar_users:
                return np.mean(self.rating_matrix[self.rating_matrix > 0])
            ratings = self.rating_matrix[list(similar_users), item_id]

        return np.average(ratings, weights=similarity_scores)

    def calc_rmse(self, test_ratings):
        actual = test_ratings[:, 2]
        predicted = np.array([self.predict_rating(uid, iid) for uid, iid, _ in test_ratings])
        return np.sqrt(np.mean((actual - predicted) ** 2))


if __name__ == "__main__":
    download_and_extract_dataset()

    ratings = load_ratings("ml-100k/u.data")

    df = pd.DataFrame(ratings, columns=['user_id', 'movie_id', 'rating'])
    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

    n_users, n_items = df['user_id'].nunique(), df['movie_id'].nunique()

    rating_matrix = lil_matrix((n_users, n_items), dtype=np.float32)
    for uid, iid, r in train_df.values:
        rating_matrix[int(uid), int(iid)] = r

    rating_matrix = rating_matrix.toarray()

    recommender = CollaborativeFiltering(rating_matrix, n=10, item_based=False)

    print("Calculating RMSE on test ratings using Collaborative Filtering...")
    print("RMSE:", recommender.calc_rmse(test_df.values))

"""# User Based and Item Based Collaborative Filtering for Matrix Completion
This code implements a collaborative filtering-based recommendation system that can operate in either user-based or item-based mode. It begins by loading and processing the MovieLens 100K dataset, where user ratings for movies are structured into a matrix. The Pearson correlation coefficient is used to measure similarity between users or items, selecting the `n` most similar ones. The system then predicts a rating for a given user-item pair using a weighted average of the ratings from these similar users or items. Finally, the accuracy of the model is evaluated by computing the Root Mean Squared Error (RMSE) on a test dataset.
"""